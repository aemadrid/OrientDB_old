---
title: Configuration and Performance tuning
layout: default
---
<ul>
  <li>
    <a href="#Introduction">Introduction</a>
  </li>
  <li>
    <a href="#General_settings">General settings</a>
  </li>
  <li style="list-style: none">
    <ul>
      <li>
        <a href="#JVM_settings">JVM settings</a>
      </li>
      <li>
        <a href="#Configuration">Configuration</a>
      </li>
      <li style="list-style: none">
        <ul>
          <li>
            <a href="#By_command_line">By command line</a>
          </li>
          <li>
            <a href="#By_server_configuration">By server
            configuration</a>
          </li>
          <li>
            <a href="#At_run-time">At run-time</a>
          </li>
          <li>
            <a href="#Parameters">Parameters</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="#Memory_optimization">Memory optimization</a>
      </li>
      <li>
        <a href="#File_System_access_strategy">File System access
        strategy</a>
      </li>
    </ul>
  </li>
  <li>
    <a href="#Remote_connections">Remote connections</a>
  </li>
  <li style="list-style: none">
    <ul>
      <li>
        <a href="#Network_Connection_Pool">Network Connection
        Pool</a>
      </li>
    </ul>
  </li>
  <li>
    <a href="#Query">Query</a>
  </li>
  <li style="list-style: none">
    <ul>
      <li>
        <a href="#Use_Indexes">Use Indexes</a>
      </li>
      <li>
        <a href="#Avoid_use_of_@rid_in_WHERE_conditions">Avoid use
        of @rid in WHERE conditions</a>
      </li>
    </ul>
  </li>
  <li>
    <a href="#Massive_Insertion">Massive Insertion</a>
  </li>
  <li style="list-style: none">
    <ul>
      <li>
        <a href="#Use_the_Massive_Insert_intent">Use the Massive
        Insert intent</a>
      </li>
    </ul>
  </li>
  <li>
    <a href="#Massive_Updates">Massive Updates</a>
  </li>
  <li style="list-style: none">
    <ul>
      <li>
        <a href="#Oversize">Oversize</a>
      </li>
    </ul>
  </li>
  <li>
    <a href="#Wise_use_of_transactions">Wise use of
    transactions</a>
  </li>
  <li style="list-style: none">
    <ul>
      <li>
        <a href="#Disable_Transaction_Log">Disable Transaction
        Log</a>
      </li>
    </ul>
  </li>
</ul>
<h2>
  <a name="Introduction" id="Introduction"></a>Introduction<a href=
  "#Introduction" class="section_anchor"></a>
</h2>
<p>
  This guide contains the general tips to optimize your application
  that use the OrientDB. Below you can find links for the specific
  guides different per database type used.
</p>
<ul>
  <li>
    <a href="performance_tuning_document.html">Document Database
    performance tuning</a>
  </li>
  <li>
    <a href="performance_tuning_object.html">Object Database
    performance tuning</a>
  </li>
  <li>
    <a href="performance_tuning_graph.html">Graph Database
    performance tuning</a>
  </li>
  <li>
    <a href="performance_tuning_blueprints.html">TinkerPop
    Blueprints Graph Database performance tuning</a>
  </li>
</ul>
<h2>
  <a name="General_settings" id="General_settings"></a>General
  settings<a href="#General_settings" class="section_anchor"></a>
</h2>
<h3>
  <a name="JVM_settings" id="JVM_settings"></a>JVM settings<a href=
  "#JVM_settings" class="section_anchor"></a>
</h3>
<p>
  The JVM settings suggested when you run your application that
  uses OrientDB are:
</p>
<pre class="prettyprint">
-server -XX:+AggressiveOpts -XX:CompileThreshold=200
</pre>
<h3>
  <a name="Configuration" id=
  "Configuration"></a>Configuration<a href="#Configuration" class=
  "section_anchor"></a>
</h3>
<p>
  OrientDB can be configured in several ways. To know the current
  configuration use the console with the <a href=
  "console_command_config.html">config command</a>.
</p>
<p>
  To dump the OrientDB configuration you can set a parameter at JVM
  launch:
</p>
<pre class="prettyprint">
java -Denvironment.dumpCfgAtStartup=true ...
</pre>
<p>
  Or via API at any time:
</p>
<pre class="prettyprint">
OGlobalConfiguration.dumpConfiguration(System.out);
</pre>
<h4>
  <a name="By_command_line" id="By_command_line"></a>By command
  line<a href="#By_command_line" class="section_anchor"></a>
</h4>
<p>
  <tt>java -Dcache.size=10000 -Dstorage.keepOpen=true ...</tt>
</p>
<h4>
  <a name="By_server_configuration" id=
  "By_server_configuration"></a>By server configuration<a href=
  "#By_server_configuration" class="section_anchor"></a>
</h4>
<p>
  Put in the <tt>&lt;properties&gt;</tt> section of the file
  <strong>orientdb-server-config.xml</strong> the entries to
  configure. Example:
</p>
<pre class="prettyprint">
  ...
  &lt;properties&gt;
    &lt;entry name="cache.size" value="10000" /&gt;
    &lt;entry name="storage.keepOpen" value="true" /&gt;
  &lt;/properties&gt;
  ...
</pre>
<h4>
  <a name="At_run-time" id="At_run-time"></a>At run-time<a href=
  "#At_run-time" class="section_anchor"></a>
</h4>
<pre class="prettyprint">
  OGlobalConfiguration.MVRBTREE_NODE_PAGE_SIZE.setValue(2048);
</pre>
<h4>
  <a name="Parameters" id="Parameters"></a>Parameters<a href=
  "#Parameters" class="section_anchor"></a>
</h4>
<p>
  To know more look at the Java enum: <a href=
  "http://code.google.com/p/orient/source/browse/trunk/core/src/main/java/com/orientechnologies/orient/core/config/OGlobalConfiguration.java"
  rel="nofollow">OGlobalConfiguration.java</a>.
</p>
<table class="zebra-striped bordered-table">
  <tr>
    <td>
      <strong>Area</strong>
    </td>
    <td>
      <strong>Parameter</strong>
    </td>
    <td>
      <strong>Default 32bit</strong>
    </td>
    <td>
      <strong>Default 64bit</strong>
    </td>
    <td>
      <strong>Default Server 32bit</strong>
    </td>
    <td>
      <strong>Default Server 64bit</strong>
    </td>
    <td>
      <strong>Allowed input</strong>
    </td>
    <td>
      <strong>Description</strong>
    </td>
  </tr>
  <tr>
    <td>
      Environment
    </td>
    <td>
      <tt>environment.dumpCfgAtStartup</tt>
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true or false
    </td>
    <td>
      Dumps the configuration at application startup
    </td>
  </tr>
  <tr>
    <td>
      Environment
    </td>
    <td>
      <tt>environment.concurrent</tt>
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true or false
    </td>
    <td>
      Specifies if running in multi-thread environment. Setting
      this to false turns off the internal lock management
    </td>
  </tr>
  <tr>
    <td>
      Memory
    </td>
    <td>
      <tt>memory.optimizeThreshold</tt>
    </td>
    <td>
      0.85
    </td>
    <td>
      0.85
    </td>
    <td>
      0.85
    </td>
    <td>
      0.85
    </td>
    <td>
      0.5-0.95
    </td>
    <td>
      Threshold of heap memory where to start the optimization of
      memory usage
    </td>
  </tr>
  <tr>
    <td>
      Storage
    </td>
    <td>
      <tt>storage.keepOpen</tt>
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true or false
    </td>
    <td>
      Tells to the engine to not close the storage when a database
      is closed. Storages will be closed when the process will
      shutdown
    </td>
  </tr>
  <tr>
    <td>
      Cache
    </td>
    <td>
      <tt>cache.level1.enabled</tt>
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      true or false
    </td>
    <td>
      Uses the level-1 cache
    </td>
  </tr>
  <tr>
    <td>
      Cache
    </td>
    <td>
      <tt>cache.level1.size</tt>
    </td>
    <td>
      -1
    </td>
    <td>
      -1
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      -1 - N
    </td>
    <td>
      Size of the Level-1 cache. -1 means no limit but when the
      free Memory Heap is low then cache entries are freed
    </td>
  </tr>
  <tr>
    <td>
      Cache
    </td>
    <td>
      <tt>cache.level2.enabled</tt>
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      true or false
    </td>
    <td>
      Uses the level-2 cache
    </td>
  </tr>
  <tr>
    <td>
      Cache
    </td>
    <td>
      <tt>cache.level2.size</tt>
    </td>
    <td>
      -1
    </td>
    <td>
      -1
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      -1 - N
    </td>
    <td>
      Size of the Level-2 cache. -1 means no limit but when the
      free Memory Heap is low then cache entries are freed
    </td>
  </tr>
  <tr>
    <td>
      Database
    </td>
    <td>
      <tt>db.mvcc</tt>
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true or false
    </td>
    <td>
      Enable Multi Version Control Checking (MVCC) or not
    </td>
  </tr>
  <tr>
    <td>
      Database
    </td>
    <td>
      <tt>object.saveOnlyDirty</tt>
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      true or false
    </td>
    <td>
      Object Database saves only object bound to dirty records
    </td>
  </tr>
  <tr>
    <td>
      Transaction
    </td>
    <td>
      <tt>tx.useLog</tt>
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true or false
    </td>
    <td>
      Transactions use log file to store temporary data to being
      rollbacked in case of crash
    </td>
  </tr>
  <tr>
    <td>
      Transaction
    </td>
    <td>
      <tt>tx.log.fileType</tt>
    </td>
    <td>
      classic
    </td>
    <td>
      classic
    </td>
    <td>
      classic
    </td>
    <td>
      classic
    </td>
    <td>
      'classic' or 'mmap'
    </td>
    <td>
      File type to handle transaction logs: mmap or classic
    </td>
  </tr>
  <tr>
    <td>
      Transaction
    </td>
    <td>
      <tt>tx.log.synch</tt>
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      true or false
    </td>
    <td>
      Executes a synch against the file-system for each log entry.
      This slows down transactions but guarantee transaction
      reliability on non-reliable drives
    </td>
  </tr>
  <tr>
    <td>
      Transaction
    </td>
    <td>
      <tt>tx.commit.synch</tt>
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true or false
    </td>
    <td>
      Synchronizes the storage after transaction commit (see
      <a href="#Disable_the_disk_synch">Disable the disk synch</a>)
    </td>
  </tr>
  <tr>
    <td>
      <a href="graph_database_tinkerpop.html">TinkerPop
      Blueprints</a>
    </td>
    <td>
      <tt>blueprints.graph.txMode</tt>
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      0 or 1
    </td>
    <td>
      Transaction mode used in <a href=
      "graph_database_tinkerpop.html">TinkerPop Blueprints</a>
      implementation. 0 = Automatic (default), 1 = Manual
    </td>
  </tr>
  <tr>
    <td>
      MVRB Tree (index and dictionary)
    </td>
    <td>
      <tt>mvrbtree.lazyUpdates</tt>
    </td>
    <td>
      20000
    </td>
    <td>
      20000
    </td>
    <td>
      1
    </td>
    <td>
      1
    </td>
    <td>
      -1=Auto, 0=always lazy until express lazySave() is called by
      application, 1=No lazy, commit at each change. &gt;1=Commit
      at every X changes
    </td>
    <td>
      Configure the MVRB Trees (indexes and dictionaries) as
      buffered or not
    </td>
  </tr>
  <tr>
    <td>
      MVRB Tree (index and dictionary)
    </td>
    <td>
      <tt>mvrbtree.nodePageSize</tt>
    </td>
    <td>
      128
    </td>
    <td>
      128
    </td>
    <td>
      128
    </td>
    <td>
      128
    </td>
    <td>
      63-65535
    </td>
    <td>
      Page size of each single node. 1,024 means that 1,024 entries
      can be stored inside a node
    </td>
  </tr>
  <tr>
    <td>
      MVRB Tree (index and dictionary)
    </td>
    <td>
      <tt>mvrbtree.loadFactor</tt>
    </td>
    <td>
      0.7f
    </td>
    <td>
      0.7f
    </td>
    <td>
      0.7f
    </td>
    <td>
      0.7f
    </td>
    <td>
      0.1-0.9
    </td>
    <td>
      HashMap load factor
    </td>
  </tr>
  <tr>
    <td>
      MVRB Tree (index and dictionary)
    </td>
    <td>
      <tt>mvrbtree.optimizeThreshold</tt>
    </td>
    <td>
      200000
    </td>
    <td>
      200000
    </td>
    <td>
      200000
    </td>
    <td>
      200000
    </td>
    <td>
      10-N
    </td>
    <td>
      Auto optimize the MVRB Tree every X operations as get, put
      and remove. -1=Auto (default)
    </td>
  </tr>
  <tr>
    <td>
      MVRB Tree (index and dictionary)
    </td>
    <td>
      <tt>mvrbtree.entryPoints</tt>
    </td>
    <td>
      16
    </td>
    <td>
      16
    </td>
    <td>
      16
    </td>
    <td>
      16
    </td>
    <td>
      1-200
    </td>
    <td>
      Number of entry points to start searching entries
    </td>
  </tr>
  <tr>
    <td>
      MVRB Tree (index and dictionary)
    </td>
    <td>
      <tt>mvrbtree.optimizeEntryPointsFactor</tt>
    </td>
    <td>
      1.0f
    </td>
    <td>
      1.0f
    </td>
    <td>
      1.0f
    </td>
    <td>
      1.0f
    </td>
    <td>
      0.1-N
    </td>
    <td>
      Multiplicand factor to apply to entry-points list (parameter
      <tt>mvrbtree.entrypoints</tt>) to determine if needs of
      optimization
    </td>
  </tr>
  <tr>
    <td>
      MVRB Tree RIDs (index and dictionary)
    </td>
    <td>
      <tt>mvrbtree.ridBinaryThreshold</tt>
    </td>
    <td>
      8
    </td>
    <td>
      8
    </td>
    <td>
      8
    </td>
    <td>
      8
    </td>
    <td>
      -1 - N
    </td>
    <td>
      Valid for set of rids. It's the threshold as number of
      entries to use the binary streaming instead of classic string
      streaming. -1 means never use binary streaming
    </td>
  </tr>
  <tr>
    <td>
      MVRB Tree RIDs (index and dictionary)
    </td>
    <td>
      <tt>mvrbtree.ridNodePageSize</tt>
    </td>
    <td>
      16
    </td>
    <td>
      16
    </td>
    <td>
      16
    </td>
    <td>
      16
    </td>
    <td>
      4 - N
    </td>
    <td>
      Page size of each treeset node. 16 means that 16 entries can
      be stored inside each node
    </td>
  </tr>
  <tr>
    <td>
      MVRB Tree RIDs (index and dictionary)
    </td>
    <td>
      <tt>mvrbtree.ridNodeSaveMemory</tt>
    </td>
    <td>
      False
    </td>
    <td>
      False
    </td>
    <td>
      False
    </td>
    <td>
      False
    </td>
    <td>
      true or false
    </td>
    <td>
      Save memory usage by avoid keeping RIDs in memory but
      creating them at every access
    </td>
  </tr>
  <tr>
    <td>
      Lazy Collections
    </td>
    <td>
      <tt>lazyset.workOnStream</tt>
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      true or false
    </td>
    <td>
      Work directly on streamed buffer to reduce memory footprint
      and improve performance
    </td>
  </tr>
  <tr>
    <td>
      File (I/O)
    </td>
    <td>
      <tt>file.lock</tt>
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true or false
    </td>
    <td>
      Locks the used files so other process can't modify them
    </td>
  </tr>
  <tr>
    <td>
      File (I/O)
    </td>
    <td>
      <tt>file.defrag.strategy</tt>
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      0,1
    </td>
    <td>
      Strategy to recycle free space. 0=recycles the first hole
      with enough size (default): fast, 1=recycles the best hole:
      better usage of space but slower
    </td>
  </tr>
  <tr>
    <td>
      File (I/O)
    </td>
    <td>
      <tt>file.defrag.holeMaxDistance</tt>
    </td>
    <td>
      32768 (32Kb)
    </td>
    <td>
      32768 (32Kb)
    </td>
    <td>
      32768 (32Kb)
    </td>
    <td>
      32768 (32Kb)
    </td>
    <td>
      8K-N
    </td>
    <td>
      Max distance in bytes between holes to execute the defrag of
      them. Set it to -1 to use dynamic size. Pay attention that is
      db is huge, then moving blocks to defrag could be expensive
    </td>
  </tr>
  <tr>
    <td>
      File (I/O)
    </td>
    <td>
      <tt>file.mmap.strategy</tt>
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      0-4
    </td>
    <td>
      Strategy to use with memory mapped files. 0 = USE MMAP
      ALWAYS, 1 = USE MMAP ON WRITES OR ON READ JUST WHEN THE BLOCK
      POOL IS FREE, 2 = USE MMAP ON WRITES OR ON READ JUST WHEN THE
      BLOCK IS ALREADY AVAILABLE, 3 = USE MMAP ONLY IF BLOCK IS
      ALREADY AVAILABLE, 4=NEVER USE MMAP
    </td>
  </tr>
  <tr>
    <td>
      File (I/O)
    </td>
    <td>
      <tt>file.mmap.blockSize</tt>
    </td>
    <td>
      1048576 (1Mb)
    </td>
    <td>
      1048576 (1Mb)
    </td>
    <td>
      1048576 (1Mb)
    </td>
    <td>
      1048576 (1Mb)
    </td>
    <td>
      10k-N
    </td>
    <td>
      Size of the memory mapped block
    </td>
  </tr>
  <tr>
    <td>
      File (I/O)
    </td>
    <td>
      <tt>file.mmap.bufferSize</tt>
    </td>
    <td>
      8192 (8Kb)
    </td>
    <td>
      8192 (8Kb)
    </td>
    <td>
      8192 (8Kb)
    </td>
    <td>
      8192 (8Kb)
    </td>
    <td>
      1K-N
    </td>
    <td>
      Size of the buffer for direct access to the file through the
      channel
    </td>
  </tr>
  <tr>
    <td>
      File (I/O)
    </td>
    <td>
      <tt>file.mmap.maxMemory</tt>
    </td>
    <td>
      134217728 (134Mb)
    </td>
    <td>
      (maxOsMemory - maxProcessHeapMemory) / 2
    </td>
    <td>
      134217728 (134Mb)
    </td>
    <td>
      (maxOsMemory - maxProcessHeapMemory) / 2
    </td>
    <td>
      100000-the maximum allowed by OS
    </td>
    <td>
      Max memory allocable by memory mapping manager. Note that on
      32bit OS the limit is to 2Gb but can change to OS by OS
    </td>
  </tr>
  <tr>
    <td>
      File (I/O)
    </td>
    <td>
      <tt>file.mmap.overlapStrategy</tt>
    </td>
    <td>
      2
    </td>
    <td>
      2
    </td>
    <td>
      2
    </td>
    <td>
      2
    </td>
    <td>
      0-2
    </td>
    <td>
      Strategy when a request overlap in-memory buffers: 0 = Use
      the channel access, 1 = force the in memory buffer and use
      the channel access, 2 = always create an overlapped in-memory
      buffer (default)
    </td>
  </tr>
  <tr>
    <td>
      File (I/O)
    </td>
    <td>
      <tt>file.mmap.forceDelay</tt>
    </td>
    <td>
      500 (0.5sec)
    </td>
    <td>
      500 (0.5sec)
    </td>
    <td>
      500 (0.5sec)
    </td>
    <td>
      500 (0.5sec)
    </td>
    <td>
      100-5000
    </td>
    <td>
      Delay time in ms to wait for another force flush of the
      memory mapped block to the disk
    </td>
  </tr>
  <tr>
    <td>
      File (I/O)
    </td>
    <td>
      <tt>file.mmap.forceRetry</tt>
    </td>
    <td>
      20
    </td>
    <td>
      20
    </td>
    <td>
      20
    </td>
    <td>
      20
    </td>
    <td>
      0-N
    </td>
    <td>
      Number of times the memory mapped block will try to flush to
      the disk
    </td>
  </tr>
  <tr>
    <td>
      Networking (I/O)
    </td>
    <td>
      <tt>network.socketBufferSize</tt>
    </td>
    <td>
      32768
    </td>
    <td>
      32768
    </td>
    <td>
      32768
    </td>
    <td>
      32768
    </td>
    <td>
      8K-N
    </td>
    <td>
      TCP/IP Socket buffer size
    </td>
  </tr>
  <tr>
    <td>
      Networking (I/O)
    </td>
    <td>
      <tt>network.timeout</tt>
    </td>
    <td>
      10000 (10secs)
    </td>
    <td>
      10000 (10secs)
    </td>
    <td>
      10000 (10secs)
    </td>
    <td>
      10000 (10secs)
    </td>
    <td>
      0-N
    </td>
    <td>
      TCP/IP Socket timeout in ms, 0=no timeout
    </td>
  </tr>
  <tr>
    <td>
      Networking (I/O)
    </td>
    <td>
      <tt>network.retry</tt>
    </td>
    <td>
      5
    </td>
    <td>
      5
    </td>
    <td>
      5
    </td>
    <td>
      5
    </td>
    <td>
      0-N
    </td>
    <td>
      Number of times the client connection retries to connect to
      the server in case of failure
    </td>
  </tr>
  <tr>
    <td>
      Networking (I/O)
    </td>
    <td>
      <tt>network.retryDelay</tt>
    </td>
    <td>
      500 (0.5sec)
    </td>
    <td>
      500 (0.5sec)
    </td>
    <td>
      500 (0.5sec)
    </td>
    <td>
      500 (0.5sec)
    </td>
    <td>
      1-N
    </td>
    <td>
      Number of ms the client wait to reconnect to the server in
      case of failure
    </td>
  </tr>
  <tr>
    <td>
      Networking (I/O)
    </td>
    <td>
      <tt>network.binary.maxLength</tt>
    </td>
    <td>
      100000 (100Kb)
    </td>
    <td>
      100000 (100Kb)
    </td>
    <td>
      100000 (100Kb)
    </td>
    <td>
      100000 (100Kb)
    </td>
    <td>
      1K-N
    </td>
    <td>
      TCP/IP max content length in bytes of BINARY requests
    </td>
  </tr>
  <tr>
    <td>
      Networking (I/O)
    </td>
    <td>
      <tt>network.binary.debug</tt>
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      true or false
    </td>
    <td>
      Debug mode: print all the incoming data on binary channel
    </td>
  </tr>
  <tr>
    <td>
      Networking (I/O)
    </td>
    <td>
      <tt>network.http.maxLength</tt>
    </td>
    <td>
      100000 (100Kb)
    </td>
    <td>
      100000 (100Kb)
    </td>
    <td>
      100000 (100Kb)
    </td>
    <td>
      100000 (100Kb)
    </td>
    <td>
      1000-N
    </td>
    <td>
      TCP/IP max content length in bytes of HTTP requests
    </td>
  </tr>
  <tr>
    <td>
      Networking (I/O)
    </td>
    <td>
      <tt>network.http.charset</tt>
    </td>
    <td>
      utf-8
    </td>
    <td>
      utf-8
    </td>
    <td>
      utf-8
    </td>
    <td>
      utf-8
    </td>
    <td>
      Supported HTTP charsets
    </td>
    <td>
      Http response charset
    </td>
  </tr>
  <tr>
    <td>
      Networking (I/O)
    </td>
    <td>
      <tt>network.http.sessionExpireTimeout</tt>
    </td>
    <td>
      60000 (1min)
    </td>
    <td>
      60000 (1min)
    </td>
    <td>
      60000 (1min)
    </td>
    <td>
      60000 (1min)
    </td>
    <td>
      0-N
    </td>
    <td>
      Timeout to consider a http session expired in ms
    </td>
  </tr>
  <tr>
    <td>
      Profiler
    </td>
    <td>
      <tt>profiler.enabled</tt>
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      true or false
    </td>
    <td>
      Enable the recording of statistics and counters
    </td>
  </tr>
  <tr>
    <td>
      Log
    </td>
    <td>
      <tt>log.console.level</tt>
    </td>
    <td>
      info
    </td>
    <td>
      info
    </td>
    <td>
      info
    </td>
    <td>
      info
    </td>
    <td>
      fine, info, warn, error
    </td>
    <td>
      Console's logging level
    </td>
  </tr>
  <tr>
    <td>
      Log
    </td>
    <td>
      <tt>log.file.level</tt>
    </td>
    <td>
      fine
    </td>
    <td>
      fine
    </td>
    <td>
      fine
    </td>
    <td>
      fine
    </td>
    <td>
      fine, info, warn, error
    </td>
    <td>
      File's logging level
    </td>
  </tr>
  <tr>
    <td>
      Client
    </td>
    <td>
      <tt>client.channel.minPool</tt>
    </td>
    <td>
      1
    </td>
    <td>
      1
    </td>
    <td>
      1
    </td>
    <td>
      1
    </td>
    <td>
      1-N
    </td>
    <td>
      Minimum size of the channel pool
    </td>
  </tr>
  <tr>
    <td>
      Client
    </td>
    <td>
      <tt>client.channel.maxPool</tt>
    </td>
    <td>
      5
    </td>
    <td>
      5
    </td>
    <td>
      5
    </td>
    <td>
      5
    </td>
    <td>
      1-N
    </td>
    <td>
      maximum size of the channel pool
    </td>
  </tr>
  <tr>
    <td>
      Server
    </td>
    <td>
      <tt>server.cache.file.static</tt>
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      false
    </td>
    <td>
      true or false
    </td>
    <td>
      Cache static resources after loaded
    </td>
  </tr>
  <tr>
    <td>
      Server
    </td>
    <td>
      <tt>server.cache.http.static</tt>
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true
    </td>
    <td>
      true or false
    </td>
    <td>
      Cache static resources setting high cache expiration in HTTP
      headers
    </td>
  </tr>
  <tr>
    <td>
      Distributed cluster
    </td>
    <td>
      <tt>distributed.async.timeDelay</tt>
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      0
    </td>
    <td>
      0-N
    </td>
    <td>
      Delay time (in ms) of synchronization with slave nodes. 0
      means early synchronization
    </td>
  </tr>
  <tr>
    <td>
      Distributed cluster
    </td>
    <td>
      <tt>distributed.sync.maxRecordsBuffer</tt>
    </td>
    <td>
      100
    </td>
    <td>
      100
    </td>
    <td>
      100
    </td>
    <td>
      100
    </td>
    <td>
      0-10000
    </td>
    <td>
      Maximum number of records to buffer before to send to the
      slave nodes
    </td>
  </tr>
</table>
<p>
  <i>NOTE: On 64-bit systems you have not the limitation of 32-bit
  systems with memory.</i>
</p>
<h3>
  <a name="Memory_optimization" id="Memory_optimization"></a>Memory
  optimization<a href="#Memory_optimization" class=
  "section_anchor"></a>
</h3>
<p>
  What can makes the difference is the right balancing between the
  heap and the virtual memory used by Memory Mapping, specially on
  large datasets (GBs, TBs and more) where the in memory cache
  structures count less than raw IO.
</p>
<p>
  For example if you can assign 4GB to the Java process, it could
  be better assigning small heap and large Virtual Memory. Rather
  than:
</p>
<pre class="prettyprint">
java -Xmx4g ...
</pre>
<p>
  You could instead try this:
</p>
<pre class="prettyprint">
java -Xmx800m -Dfile.mmap.maxMemory=3.2gb ...
</pre>
<p>
  The parameter <strong>file.mmap.maxMemory</strong> tells how much
  memory to use for the Memory Mapping at the storage level. The
  default value for 32-bit systems is very tiny (134 Mb) but with
  32-bit architecture you have a lot of limitation and you need to
  pay attention to set it too large. On 64 bit systems I suggest to
  set it to: <tt>( os tot memory - orientdb heap ) * 85%</tt>. 85%
  should be reduced when you're running other memory expensive
  process on your OS.
</p>
<p>
  On 64 bit systems the default value is <tt>(maxOsMemory -
  maxProcessHeapMemory) / 2</tt>.
</p>
<p>
  <i>NOTE: If you use too much memory your system will goes in swap
  and the entire machine will slow down. Play with this parameter
  in order to find the best value for your configuration.</i>
</p>
<h3>
  <a name="File_System_access_strategy" id=
  "File_System_access_strategy"></a>File System access
  strategy<a href="#File_System_access_strategy" class=
  "section_anchor"></a>
</h3>
<p>
  This is more technical. It tells to the storage engine the
  strategy to use when access to the file system. Previous versions
  always used the 0 strategy, namely uses Memory Mapping techniques
  for all. Mode 1 tells to use Memory Mapping but on reads only if
  there is room in memory, otherwise regular Java NIO file channel
  read will be used. The strategy 2 is more conservative since
  reads will use Memory Mapping only if the requested data has
  already been loaded in memory. The strategy 3 means use Memory
  Mapping until there is space in the pool, then use regular Java
  NIO file channel read/write. Strategy 4 means don't use Memory
  Mapping at all.
</p>
<p>
  By default the strategy 1 is used, but feel free to test the
  others to know what is the best for your use case.
</p>
<h2>
  <a name="Remote_connections" id="Remote_connections"></a>Remote
  connections<a href="#Remote_connections" class=
  "section_anchor"></a>
</h2>
<p>
  There are many ways to improve performance when you access to the
  database using the remote connection.
</p>
<h3>
  <a name="Network_Connection_Pool" id=
  "Network_Connection_Pool"></a>Network Connection Pool<a href=
  "#Network_Connection_Pool" class="section_anchor"></a>
</h3>
<p>
  Each client, by default, uses only one network connection to talk
  with the server. Multiple threads on the same client share the
  same network connection pool.
</p>
<p>
  When you've multiple threads could be a bottleneck since a lot of
  time is spent on waiting for a free network connection. This is
  the reason why is much important to configure the network
  connection pool.
</p>
<p>
  The configurations is very simple, just 2 parameters:
</p>
<ul>
  <li>
    <strong>minPool</strong>, is the initial size of the connection
    pool. The default value is configured as global parameters
    "client.channel.minPool" (see <a href=
    "#Parameters">parameters</a>)
  </li>
  <li>
    <strong>maxPool</strong>, is the maximum size the connection
    pool can reach. The default value is configured as global
    parameters "client.channel.maxPool" (see <a href=
    "#Parameters">parameters</a>)
  </li>
</ul>
<p>
  At first connection the <strong>minPool</strong> is used to
  pre-create network connections against the server. When a client
  thread is asking for a connection and all the pool is busy, then
  it tries to create a new connection until
  <strong>maxPool</strong> is reached.
</p>
<p>
  If all the pool connections are busy, then the client thread will
  wait for the first free connection.
</p>
<p>
  Example of configuration by using database properties:
</p>
<pre class="prettyprint">
database = new ODatabaseDocumentTx("remote:localhost/demo");
database.setProperty("minPool", 2);
database.setProperty("maxPool", 5);

database.open("admin", "admin");
</pre>
<h2>
  <a name="Query" id="Query"></a>Query<a href="#Query" class=
  "section_anchor"></a>
</h2>
<h3>
  <a name="Use_Indexes" id="Use_Indexes"></a>Use Indexes<a href=
  "#Use_Indexes" class="section_anchor"></a>
</h3>
<p>
  The first improvement to speed up queries is to create <a href=
  "indexes.html">indexes</a> against the fields used in WHERE
  conditions. For example this query:
</p>
<pre class="prettyprint">
SELECT FROM Profile WHERE name = 'Jay'
</pre>
<p>
  Browses the entire "profile" cluster looking for records that
  satisfy the conditions. The solution is to create an index
  against the 'name' property with:
</p>
<pre class="prettyprint">
CREATE INDEX profile.name UNIQUE
</pre>
<p>
  Use NOTUNIQUE instead of UNIQUE if the value is not unique.
</p>
<p>
  For more complex queries like
</p>
<pre class="prettyprint">
select * from testClass where prop1 = ? and prop2 = ?
</pre>
<p>
  Composite index should be used
</p>
<pre class="prettyprint">
CREATE INDEX compositeIndex ON testClass (prop1, prop2) UNIQUE
</pre>
<p>
  or via Java API:
</p>
<pre class="prettyprint">
oClass.createIndex("compositeIndex", OClass.INDEX_TYPE.UNIQUE, "prop1", "prop2");
</pre>
<p>
  Moreover, because of partial match searching, this index will be
  used for optimizing query like
</p>
<pre class="prettyprint">
select * from testClass where prop1 = ?
</pre>
<p>
  For deep understanding of query optimization look at the unit
  test: <a href=
  "http://code.google.com/p/orient/source/browse/trunk/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectIndexReuseTest.java"
  rel=
  "nofollow">http://code.google.com/p/orient/source/browse/trunk/tests/src/test/java/com/orientechnologies/orient/test/database/auto/SQLSelectIndexReuseTest.java</a>
</p>
<h3>
  <a name="Avoid_use_of_@rid_in_WHERE_conditions"></a>Avoid use of
  @rid in WHERE conditions<a href=
  "#Avoid_use_of_@rid_in_WHERE_conditions" class=
  "section_anchor"></a>
</h3>
<p>
  Using <strong>@rid</strong> in where conditions slow down
  queries. Much better to use the <a href=
  "concepts.html#RecordID">RecordID</a> as target. Example:
</p>
<p>
  Change this:
</p>
<pre class="prettyprint">
SELECT FROM Profile WHERE @rid = #10:44
</pre>
<p>
  With this:
</p>
<pre class="prettyprint">
SELECT FROM #10:44
</pre>
<p>
  Also
</p>
<pre class="prettyprint">
SELECT FROM Profile WHERE @rid IN [#10:44, #10:45]
</pre>
<p>
  With this:
</p>
<pre class="prettyprint">
SELECT FROM [#10:44, #10:45]
</pre>
<h2>
  <a name="Massive_Insertion" id="Massive_Insertion"></a>Massive
  Insertion<a href="#Massive_Insertion" class="section_anchor"></a>
</h2>
<h3>
  <a name="Use_the_Massive_Insert_intent" id=
  "Use_the_Massive_Insert_intent"></a>Use the Massive Insert
  intent<a href="#Use_the_Massive_Insert_intent" class=
  "section_anchor"></a>
</h3>
<p>
  Intents suggest to OrientDB what you're going to do. In this case
  you're telling to OrientDB that you're executing a massive
  insertion. OrientDB auto-reconfigure itself to obtain the best
  performance. When done you can remove the intent just setting it
  to null.
</p>
<p>
  Example:
</p>
<pre class="prettyprint">
db.declareIntent( new OIntentMassiveInsert() );

// YOUR MASSIVE INSERTION

db.declareIntent( null );
</pre>
<h2>
  <a name="Massive_Updates" id="Massive_Updates"></a>Massive
  Updates<a href="#Massive_Updates" class="section_anchor"></a>
</h2>
<p>
  Updates generates "holes" at Storage level because rarely the new
  record fits perfectly the size of the previous one. Holes are
  free spaces between data. Holes are recycled but an excessive
  number of small holes it's the same as having a highly
  defragmented File System: space is wasted (because small holes
  can't be easily recycled) and performance degrades when the
  database growth.
</p>
<h3>
  <a name="Oversize" id="Oversize"></a>Oversize<a href="#Oversize"
  class="section_anchor"></a>
</h3>
<p>
  If you know you will update certain type of records, create a
  class for them and set the Oversize (default is 0) to 2 or more.
</p>
<p>
  By default the OGraphVertex class has an oversize value setted at
  2. If you define your own classes set this value at least at 2.
</p>
<p>
  OClass myClass = getMetadata().getSchema().createClass("Car");
  myClass.setOverSize(2);
</p>
<h2>
  <a name="Wise_use_of_transactions" id=
  "Wise_use_of_transactions"></a>Wise use of transactions<a href=
  "#Wise_use_of_transactions" class="section_anchor"></a>
</h2>
<p>
  To obtain real linear performance with OrientDB you should avoid
  to use <a href="transactions.html">Transactions</a> as far you
  can. In facts OrientDB keeps in memory all the changes until you
  flush it with a commit. So the bottleneck is your Heap space and
  the management of local transaction cache (implemented as a Map).
</p>
<p>
  <a href="transactions.html">Transactions</a> slow down massive
  inserts unless you're using a "remote" connection. In that case
  it speeds up all the insertion because the client/server
  communication happens only at commit time.
</p>
<h3>
  <a name="Disable_Transaction_Log" id=
  "Disable_Transaction_Log"></a>Disable Transaction Log<a href=
  "#Disable_Transaction_Log" class="section_anchor"></a>
</h3>
<p>
  If you need to group operations to speed up remote execution in a
  logical transaction but renouncing to the Transaction Log, just
  disable it by setting the property <strong>tx.useLog</strong> to
  false.
</p>
<p>
  Via JVM configuration:
</p>
<pre class="prettyprint">
java ... -Dtx.useLog=false ...
</pre>
<p>
  or via API:
</p>
<pre class="prettyprint">
OGlobalConfiguration.TX_USE_LOG.setValue(false);
</pre>
<p>
  <i>NOTE: Please note that in case of crash of the JVM the pending
  transaction OrientDB could not be able to rollback it.</i>
</p>
